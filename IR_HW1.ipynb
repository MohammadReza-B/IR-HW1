{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='skyblue'>HW-1 _ Information Retrieval\n",
    "\n",
    "MohammadReza\n",
    "\n",
    "May - 2023\n",
    "<font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Opening stopword.txt file and store each word in a list.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 542\n",
      "Some of stopwords: \n",
      " ['a', 'associates', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after']\n"
     ]
    }
   ],
   "source": [
    "with open('stopwords.txt', 'r') as stopwords_file:\n",
    "    stopwords = stopwords_file.read().split()\n",
    "\n",
    "\n",
    "print('Number of stopwords:', len(stopwords))\n",
    "print('Some of stopwords: \\n', stopwords[0:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='yellow'>-----------------------PART 1: PARSING-----------------------</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening 3 folders:\n",
    "\n",
    "#### 2007, 2008, 2009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 2007 cars:  227\n",
      "Number of 2008 cars:  228\n",
      "Number of 2009 cars:  143\n"
     ]
    }
   ],
   "source": [
    "# Use the os module to get a list of all files in the folder.\n",
    "import os\n",
    "path_2007 = './cars/2007'\n",
    "car_2007_names = os.listdir(path_2007)\n",
    "print('Number of 2007 cars: ', len(car_2007_names))\n",
    "\n",
    "path_2008 = './cars/2008'\n",
    "car_2008_names = os.listdir(path_2008)\n",
    "print('Number of 2008 cars: ', len(car_2008_names))\n",
    "\n",
    "path_2009 = './cars/2009'\n",
    "car_2009_names = os.listdir(path_2009)\n",
    "print('Number of 2009 cars: ', len(car_2009_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "favorite_list = []\n",
    "doc_id_list = []\n",
    "doc_id = 11111\n",
    "\n",
    "\n",
    "def reset_list():\n",
    "    global text_list, favorite_list, doc_id_list, doc_id\n",
    "    text_list = []\n",
    "    favorite_list = []\n",
    "    doc_id_list = []\n",
    "    doc_id = 11111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_list(file_name, data):\n",
    "    global text_list, favorite_list, doc_id_list, doc_id\n",
    "\n",
    "    doc_regex = re.compile(r'<DOC>.*?</DOC>', re.DOTALL)\n",
    "    doc_matches = doc_regex.findall(data)\n",
    "\n",
    "    for match in doc_matches:\n",
    "        text_regex = re.compile(r'<TEXT>(.*?)</TEXT>')\n",
    "        text_match = text_regex.search(match)\n",
    "        if text_match:\n",
    "            text_list.append(text_match.group(1))\n",
    "            doc_id_list.append(file_name + '_' + str(doc_id))\n",
    "            doc_id += 1\n",
    "        else:\n",
    "            text_list.append(\"\")\n",
    "            doc_id_list.append(file_name + '_' + str(doc_id))\n",
    "            doc_id += 1\n",
    "\n",
    "        fav_regex = re.compile(r'<FAVORITE>(.*?)</FAVORITE>')\n",
    "        fav_match = fav_regex.search(match)\n",
    "        if fav_match:\n",
    "            favorite_list.append(fav_match.group(1))\n",
    "        else:\n",
    "            favorite_list.append(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_2007_DOC = pd.DataFrame()\n",
    "cars_2008_DOC = pd.DataFrame()\n",
    "cars_2009_DOC = pd.DataFrame()\n",
    "\n",
    "\n",
    "def make_df(year):\n",
    "    # Create a Pandas DataFrame from the lists\n",
    "    global cars_2007_DOC\n",
    "    global cars_2008_DOC\n",
    "    global cars_2009_DOC\n",
    "    if year == 2007:\n",
    "        cars_2007_DOC = pd.DataFrame({\n",
    "            'DOCID': doc_id_list,\n",
    "            'TEXT': text_list,\n",
    "            'FAVORITE': favorite_list\n",
    "        })\n",
    "\n",
    "    elif year == 2008:\n",
    "        cars_2008_DOC = pd.DataFrame({\n",
    "            'DOCID': doc_id_list,\n",
    "            'TEXT': text_list,\n",
    "            'FAVORITE': favorite_list\n",
    "        })\n",
    "    elif year == 2009:\n",
    "        cars_2009_DOC = pd.DataFrame({\n",
    "            'DOCID': doc_id_list,\n",
    "            'TEXT': text_list,\n",
    "            'FAVORITE': favorite_list\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the chardet library to detect the encoding of the file.\n",
    "import chardet\n",
    "\n",
    "\"\"\" \n",
    "  The first part of the code reads the file in binary mode and uses chardet to detect the encoding.\n",
    "  The second part of the code reads the file in text mode with the detected encoding.\n",
    "\"\"\"\n",
    "# 2007 folder:\n",
    "reset_list()  # Clear the lists\n",
    "for filename in car_2007_names:\n",
    "    file_path = os.path.join(path_2007, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        encoding = chardet.detect(file.read())['encoding']\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        file_data = file.read()\n",
    "        add_to_list(filename, file_data)\n",
    "\n",
    "make_df(2007)\n",
    "\n",
    "# 2008 folder:\n",
    "reset_list()  # Clear the lists\n",
    "for filename in car_2008_names:\n",
    "    file_path = os.path.join(path_2008, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        encoding = chardet.detect(file.read())['encoding']\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        file_data = file.read()\n",
    "        add_to_list(filename, file_data)\n",
    "\n",
    "make_df(2008)\n",
    "\n",
    "# 2009 folder:\n",
    "reset_list()  # Clear the lists\n",
    "for filename in car_2009_names:\n",
    "    file_path = os.path.join(path_2009, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        encoding = chardet.detect(file.read())['encoding']\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        file_data = file.read()\n",
    "        add_to_list(filename, file_data)\n",
    "\n",
    "make_df(2009)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx_11111</td>\n",
       "      <td>I just moved to Germany two months ago and bou...</td>\n",
       "      <td>The separate controls for the rear passengers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx_11112</td>\n",
       "      <td>After months of careful research and test driv...</td>\n",
       "      <td>The self-adjusting side mirrors which rotate t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx_11113</td>\n",
       "      <td>I'm two years into a three year lease and I lo...</td>\n",
       "      <td>Navi is easy, hands-free is great, AWD is perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx_11114</td>\n",
       "      <td>First luxury crossover SUV I have owned. MDX w...</td>\n",
       "      <td>AWD system, exterior styling, cargo room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx_11115</td>\n",
       "      <td>This is the first Japanese SUV we have had in ...</td>\n",
       "      <td>Navigation, sound system, bluetooth, comfort, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>2007_volvo_xc90_30009</td>\n",
       "      <td>I have been a loyal Volvo customer (3 Cross Co...</td>\n",
       "      <td>Safety, plenty of room, great convenience feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>2007_volvo_xc90_30010</td>\n",
       "      <td>this car is probably the best vehicle I have o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>2007_volvo_xc90_30011</td>\n",
       "      <td>This is my first Volvo purchase and so far so ...</td>\n",
       "      <td>Leather seats, extra large trunk space (for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>2007_volvo_xc90_30012</td>\n",
       "      <td>This is a great car....tons of power with new ...</td>\n",
       "      <td>Bi xenon headlights, AWD w/ instant traction, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>2007_volvo_xc90_30013</td>\n",
       "      <td>I recently bought an 2007 Volvo XC90 with the ...</td>\n",
       "      <td>The stares I get from women thinking I have a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18903 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DOCID  \\\n",
       "0       2007_acura_mdx_11111   \n",
       "1       2007_acura_mdx_11112   \n",
       "2       2007_acura_mdx_11113   \n",
       "3       2007_acura_mdx_11114   \n",
       "4       2007_acura_mdx_11115   \n",
       "...                      ...   \n",
       "18898  2007_volvo_xc90_30009   \n",
       "18899  2007_volvo_xc90_30010   \n",
       "18900  2007_volvo_xc90_30011   \n",
       "18901  2007_volvo_xc90_30012   \n",
       "18902  2007_volvo_xc90_30013   \n",
       "\n",
       "                                                    TEXT  \\\n",
       "0      I just moved to Germany two months ago and bou...   \n",
       "1      After months of careful research and test driv...   \n",
       "2      I'm two years into a three year lease and I lo...   \n",
       "3      First luxury crossover SUV I have owned. MDX w...   \n",
       "4      This is the first Japanese SUV we have had in ...   \n",
       "...                                                  ...   \n",
       "18898  I have been a loyal Volvo customer (3 Cross Co...   \n",
       "18899  this car is probably the best vehicle I have o...   \n",
       "18900  This is my first Volvo purchase and so far so ...   \n",
       "18901  This is a great car....tons of power with new ...   \n",
       "18902  I recently bought an 2007 Volvo XC90 with the ...   \n",
       "\n",
       "                                                FAVORITE  \n",
       "0      The separate controls for the rear passengers ...  \n",
       "1      The self-adjusting side mirrors which rotate t...  \n",
       "2      Navi is easy, hands-free is great, AWD is perf...  \n",
       "3               AWD system, exterior styling, cargo room  \n",
       "4      Navigation, sound system, bluetooth, comfort, ...  \n",
       "...                                                  ...  \n",
       "18898  Safety, plenty of room, great convenience feat...  \n",
       "18899                                                     \n",
       "18900  Leather seats, extra large trunk space (for a ...  \n",
       "18901  Bi xenon headlights, AWD w/ instant traction, ...  \n",
       "18902  The stares I get from women thinking I have a ...  \n",
       "\n",
       "[18903 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_2007_DOC\n",
    "# cars_2008_DOC\n",
    "# cars_2009_DOC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of document 2007: 18903\n",
      "number of document 2008: 15438\n",
      "number of document 2009: 7947\n"
     ]
    }
   ],
   "source": [
    "print('number of document 2007:', len(cars_2007_DOC))\n",
    "print('number of document 2008:', len(cars_2008_DOC))\n",
    "print('number of document 2009:', len(cars_2009_DOC))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='yellow'>-----------------------PART 2: PREPROCESSING-----------------------</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Remove punctuation and convert to lowercase letters:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove puncutation 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(remove_punctuation)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(remove_punctuation)\n",
    "# lowercase 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(lower_case)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(lower_case)\n",
    "\n",
    "# Remove puncutation 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(remove_punctuation)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(remove_punctuation)\n",
    "# lowercase 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(lower_case)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(lower_case)\n",
    "\n",
    "# Remove puncutation 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(remove_punctuation)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(remove_punctuation)\n",
    "# lowercase 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(lower_case)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(lower_case)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Removing Numbers:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i just moved to germany two months ago and bought an 07 mdx from another military member it has everything i could want we just returned from a week driving through the alps and this suv is simply amazing granted i get to drive it much faster than i could in the states but even at 120 mph it was rock solid we need the awd for the snow and the kids stay entertained with the av system plenty of passing power and very comfortable on long trips acuras are rare in germany and i get stares all the time by curious bavarians wondering what kind of vehicle i have if you are in the market for a luxury suv for family touring with cool tech toys to play with mdx cant be beat '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    res = ''\n",
    "    for char in text:\n",
    "     if not char.isdigit():\n",
    "          res += char\n",
    "          \n",
    "    return res\n",
    "cars_2007_DOC['TEXT'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_numbers 2007\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(remove_numbers)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(remove_numbers)\n",
    "# remove_numbers 2008\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(remove_numbers)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(remove_numbers)\n",
    "# remove_numbers 2009\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(remove_numbers)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i just moved to germany two months ago and bought an  mdx from another military member it has everything i could want we just returned from a week driving through the alps and this suv is simply amazing granted i get to drive it much faster than i could in the states but even at  mph it was rock solid we need the awd for the snow and the kids stay entertained with the av system plenty of passing power and very comfortable on long trips acuras are rare in germany and i get stares all the time by curious bavarians wondering what kind of vehicle i have if you are in the market for a luxury suv for family touring with cool tech toys to play with mdx cant be beat '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_2007_DOC['TEXT'].iloc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Removing Stopwords:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    # Tokenize the input text\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove the stop words\n",
    "    filtered_text = [word for word in word_tokens if not word in stopwords]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_text)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(remove_stopwords)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(remove_stopwords)\n",
    "\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(remove_stopwords)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(remove_stopwords)\n",
    "\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(remove_stopwords)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx_11111</td>\n",
       "      <td>moved germany months ago bought mdx military m...</td>\n",
       "      <td>separate controls rear passengers awesome cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx_11112</td>\n",
       "      <td>months careful research test drives bmw lexus ...</td>\n",
       "      <td>selfadjusting side mirrors rotate give view cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx_11113</td>\n",
       "      <td>im years year lease love car thing change shap...</td>\n",
       "      <td>navi easy handsfree great awd perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx_11114</td>\n",
       "      <td>luxury crossover suv owned mdx won lexus cost ...</td>\n",
       "      <td>awd system exterior styling cargo room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx_11115</td>\n",
       "      <td>japanese suv suvs yukon xl envoy xl beats perf...</td>\n",
       "      <td>navigation sound system bluetooth comfort acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>2007_volvo_xc90_30009</td>\n",
       "      <td>loyal volvo customer cross countrys years feel...</td>\n",
       "      <td>safety plenty room great convenience features ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>2007_volvo_xc90_30010</td>\n",
       "      <td>car vehicle owned feel beats fx safest suv road</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>2007_volvo_xc90_30011</td>\n",
       "      <td>volvo purchase good love exterior aesthetics i...</td>\n",
       "      <td>leather seats extra large trunk space midsize suv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>2007_volvo_xc90_30012</td>\n",
       "      <td>great cartons power speed autoluxurious interi...</td>\n",
       "      <td>bi xenon headlights awd instant traction navi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>2007_volvo_xc90_30013</td>\n",
       "      <td>recently bought volvo xc cylinder motor sluggi...</td>\n",
       "      <td>stares women thinking large income thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18903 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DOCID  \\\n",
       "0       2007_acura_mdx_11111   \n",
       "1       2007_acura_mdx_11112   \n",
       "2       2007_acura_mdx_11113   \n",
       "3       2007_acura_mdx_11114   \n",
       "4       2007_acura_mdx_11115   \n",
       "...                      ...   \n",
       "18898  2007_volvo_xc90_30009   \n",
       "18899  2007_volvo_xc90_30010   \n",
       "18900  2007_volvo_xc90_30011   \n",
       "18901  2007_volvo_xc90_30012   \n",
       "18902  2007_volvo_xc90_30013   \n",
       "\n",
       "                                                    TEXT  \\\n",
       "0      moved germany months ago bought mdx military m...   \n",
       "1      months careful research test drives bmw lexus ...   \n",
       "2      im years year lease love car thing change shap...   \n",
       "3      luxury crossover suv owned mdx won lexus cost ...   \n",
       "4      japanese suv suvs yukon xl envoy xl beats perf...   \n",
       "...                                                  ...   \n",
       "18898  loyal volvo customer cross countrys years feel...   \n",
       "18899    car vehicle owned feel beats fx safest suv road   \n",
       "18900  volvo purchase good love exterior aesthetics i...   \n",
       "18901  great cartons power speed autoluxurious interi...   \n",
       "18902  recently bought volvo xc cylinder motor sluggi...   \n",
       "\n",
       "                                                FAVORITE  \n",
       "0      separate controls rear passengers awesome cont...  \n",
       "1      selfadjusting side mirrors rotate give view cu...  \n",
       "2                  navi easy handsfree great awd perfect  \n",
       "3                 awd system exterior styling cargo room  \n",
       "4      navigation sound system bluetooth comfort acce...  \n",
       "...                                                  ...  \n",
       "18898  safety plenty room great convenience features ...  \n",
       "18899                                                     \n",
       "18900  leather seats extra large trunk space midsize suv  \n",
       "18901  bi xenon headlights awd instant traction navi ...  \n",
       "18902           stares women thinking large income thing  \n",
       "\n",
       "[18903 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_2007_DOC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Tokenization and Lemmatization:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(tokenize)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(tokenize)\n",
    "# Lemmatization 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "# Tokenize 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(tokenize)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(tokenize)\n",
    "# Lemmatization 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "# Tokenize 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(tokenize)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(tokenize)\n",
    "# Lemmatization 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moved', 'germany', 'month', 'ago', 'bought', 'mdx', 'military', 'member', 'returned', 'week', 'driving', 'alp', 'suv', 'simply', 'amazing', 'granted', 'drive', 'faster', 'state', 'mph', 'rock', 'solid', 'awd', 'snow', 'kid', 'stay', 'entertained', 'av', 'system', 'plenty', 'passing', 'power', 'comfortable', 'long', 'trip', 'acuras', 'rare', 'germany', 'stare', 'time', 'curious', 'bavarian', 'wondering', 'kind', 'vehicle', 'market', 'luxury', 'suv', 'family', 'touring', 'cool', 'tech', 'toy', 'play', 'mdx', 'beat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx_11111</td>\n",
       "      <td>[moved, germany, month, ago, bought, mdx, mili...</td>\n",
       "      <td>[separate, control, rear, passenger, awesome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx_11112</td>\n",
       "      <td>[month, careful, research, test, drive, bmw, l...</td>\n",
       "      <td>[selfadjusting, side, mirror, rotate, give, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx_11113</td>\n",
       "      <td>[im, year, year, lease, love, car, thing, chan...</td>\n",
       "      <td>[navi, easy, handsfree, great, awd, perfect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx_11114</td>\n",
       "      <td>[luxury, crossover, suv, owned, mdx, won, lexu...</td>\n",
       "      <td>[awd, system, exterior, styling, cargo, room]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx_11115</td>\n",
       "      <td>[japanese, suv, suv, yukon, xl, envoy, xl, bea...</td>\n",
       "      <td>[navigation, sound, system, bluetooth, comfort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>2007_volvo_xc90_30009</td>\n",
       "      <td>[loyal, volvo, customer, cross, country, year,...</td>\n",
       "      <td>[safety, plenty, room, great, convenience, fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>2007_volvo_xc90_30010</td>\n",
       "      <td>[car, vehicle, owned, feel, beat, fx, safest, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>2007_volvo_xc90_30011</td>\n",
       "      <td>[volvo, purchase, good, love, exterior, aesthe...</td>\n",
       "      <td>[leather, seat, extra, large, trunk, space, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>2007_volvo_xc90_30012</td>\n",
       "      <td>[great, carton, power, speed, autoluxurious, i...</td>\n",
       "      <td>[bi, xenon, headlight, awd, instant, traction,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>2007_volvo_xc90_30013</td>\n",
       "      <td>[recently, bought, volvo, xc, cylinder, motor,...</td>\n",
       "      <td>[stare, woman, thinking, large, income, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18903 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       DOCID  \\\n",
       "0       2007_acura_mdx_11111   \n",
       "1       2007_acura_mdx_11112   \n",
       "2       2007_acura_mdx_11113   \n",
       "3       2007_acura_mdx_11114   \n",
       "4       2007_acura_mdx_11115   \n",
       "...                      ...   \n",
       "18898  2007_volvo_xc90_30009   \n",
       "18899  2007_volvo_xc90_30010   \n",
       "18900  2007_volvo_xc90_30011   \n",
       "18901  2007_volvo_xc90_30012   \n",
       "18902  2007_volvo_xc90_30013   \n",
       "\n",
       "                                                    TEXT  \\\n",
       "0      [moved, germany, month, ago, bought, mdx, mili...   \n",
       "1      [month, careful, research, test, drive, bmw, l...   \n",
       "2      [im, year, year, lease, love, car, thing, chan...   \n",
       "3      [luxury, crossover, suv, owned, mdx, won, lexu...   \n",
       "4      [japanese, suv, suv, yukon, xl, envoy, xl, bea...   \n",
       "...                                                  ...   \n",
       "18898  [loyal, volvo, customer, cross, country, year,...   \n",
       "18899  [car, vehicle, owned, feel, beat, fx, safest, ...   \n",
       "18900  [volvo, purchase, good, love, exterior, aesthe...   \n",
       "18901  [great, carton, power, speed, autoluxurious, i...   \n",
       "18902  [recently, bought, volvo, xc, cylinder, motor,...   \n",
       "\n",
       "                                                FAVORITE  \n",
       "0      [separate, control, rear, passenger, awesome, ...  \n",
       "1      [selfadjusting, side, mirror, rotate, give, vi...  \n",
       "2           [navi, easy, handsfree, great, awd, perfect]  \n",
       "3          [awd, system, exterior, styling, cargo, room]  \n",
       "4      [navigation, sound, system, bluetooth, comfort...  \n",
       "...                                                  ...  \n",
       "18898  [safety, plenty, room, great, convenience, fea...  \n",
       "18899                                                 []  \n",
       "18900  [leather, seat, extra, large, trunk, space, mi...  \n",
       "18901  [bi, xenon, headlight, awd, instant, traction,...  \n",
       "18902     [stare, woman, thinking, large, income, thing]  \n",
       "\n",
       "[18903 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "print(cars_2007_DOC['TEXT'].iloc[0])\n",
    "cars_2007_DOC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='yellow'>-----------------------PART 3: INVERTED INDEX-----------------------</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx_11111</td>\n",
       "      <td>[moved, germany, month, ago, bought, mdx, mili...</td>\n",
       "      <td>[separate, control, rear, passenger, awesome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx_11112</td>\n",
       "      <td>[month, careful, research, test, drive, bmw, l...</td>\n",
       "      <td>[selfadjusting, side, mirror, rotate, give, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx_11113</td>\n",
       "      <td>[im, year, year, lease, love, car, thing, chan...</td>\n",
       "      <td>[navi, easy, handsfree, great, awd, perfect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx_11114</td>\n",
       "      <td>[luxury, crossover, suv, owned, mdx, won, lexu...</td>\n",
       "      <td>[awd, system, exterior, styling, cargo, room]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx_11115</td>\n",
       "      <td>[japanese, suv, suv, yukon, xl, envoy, xl, bea...</td>\n",
       "      <td>[navigation, sound, system, bluetooth, comfort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>2009_volvo_c70_19053</td>\n",
       "      <td>[vw, driver, year, talked, vw, lease, expired,...</td>\n",
       "      <td>[hardtop, roof, trunk, space, awesome, convert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7943</th>\n",
       "      <td>2009_volvo_c70_19054</td>\n",
       "      <td>[handle, beautiful, fun, drive, surprised, lar...</td>\n",
       "      <td>[retractable, hardtop, great, operates, quickl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>2009_volvo_c70_19055</td>\n",
       "      <td>[excellent, exterior, interior, styling, inter...</td>\n",
       "      <td>[styling, fantastic, sound, system, big, trunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>2009_volvo_c70_19056</td>\n",
       "      <td>[smooth, handling, headturning, style, handinh...</td>\n",
       "      <td>[broad, shouldered, stylinga, dynamic, audio, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7946</th>\n",
       "      <td>2009_volvo_c70_19057</td>\n",
       "      <td>[smooth, silk, shifting, manual, speed, excell...</td>\n",
       "      <td>[huge, trunk, smooth, speed, shifting, nice, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42288 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DOCID                                               TEXT  \\\n",
       "0     2007_acura_mdx_11111  [moved, germany, month, ago, bought, mdx, mili...   \n",
       "1     2007_acura_mdx_11112  [month, careful, research, test, drive, bmw, l...   \n",
       "2     2007_acura_mdx_11113  [im, year, year, lease, love, car, thing, chan...   \n",
       "3     2007_acura_mdx_11114  [luxury, crossover, suv, owned, mdx, won, lexu...   \n",
       "4     2007_acura_mdx_11115  [japanese, suv, suv, yukon, xl, envoy, xl, bea...   \n",
       "...                    ...                                                ...   \n",
       "7942  2009_volvo_c70_19053  [vw, driver, year, talked, vw, lease, expired,...   \n",
       "7943  2009_volvo_c70_19054  [handle, beautiful, fun, drive, surprised, lar...   \n",
       "7944  2009_volvo_c70_19055  [excellent, exterior, interior, styling, inter...   \n",
       "7945  2009_volvo_c70_19056  [smooth, handling, headturning, style, handinh...   \n",
       "7946  2009_volvo_c70_19057  [smooth, silk, shifting, manual, speed, excell...   \n",
       "\n",
       "                                               FAVORITE  \n",
       "0     [separate, control, rear, passenger, awesome, ...  \n",
       "1     [selfadjusting, side, mirror, rotate, give, vi...  \n",
       "2          [navi, easy, handsfree, great, awd, perfect]  \n",
       "3         [awd, system, exterior, styling, cargo, room]  \n",
       "4     [navigation, sound, system, bluetooth, comfort...  \n",
       "...                                                 ...  \n",
       "7942  [hardtop, roof, trunk, space, awesome, convert...  \n",
       "7943  [retractable, hardtop, great, operates, quickl...  \n",
       "7944  [styling, fantastic, sound, system, big, trunk...  \n",
       "7945  [broad, shouldered, stylinga, dynamic, audio, ...  \n",
       "7946  [huge, trunk, smooth, speed, shifting, nice, d...  \n",
       "\n",
       "[42288 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the data frames vertically\n",
    "all_cars_DOC = pd.concat([cars_2007_DOC, cars_2008_DOC, cars_2009_DOC], axis=0)\n",
    "all_cars_DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(col):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    # Create a defaultdict to store the inverted index\n",
    "    inv_indx = defaultdict(list)\n",
    "\n",
    "    # Create a defaultdict to store the document frequency\n",
    "    doc_freq = defaultdict(int)\n",
    "\n",
    "    # Iterate over the documents\n",
    "    for idx, text in enumerate(all_cars_DOC[col]):\n",
    "        # Get the ID of the dataframe\n",
    "        doc_id = all_cars_DOC.iloc[idx]['DOCID']\n",
    "        # Iterate over the words in the document\n",
    "        for word in set(text):\n",
    "            # Update the inverted index\n",
    "            inv_indx[word].append((doc_id, text.count(word)))\n",
    "            # Update the document frequency\n",
    "            doc_freq[word] += 1\n",
    "\n",
    "    # Sort the postings for each word by their document frequency\n",
    "    inv_indx = {word: sorted(postings, key=lambda x: x[1]) for word, postings in inv_indx.items()}\n",
    "\n",
    "    # Sort the inverted index by document frequency in ascending order\n",
    "    inv_indx = sorted(inv_indx.items(), key=lambda x: doc_freq[x[0]])\n",
    "\n",
    "    # Write the inverted index to a text file\n",
    "    with open(str(col) + '_' + 'inverted_index.txt', 'w') as f:\n",
    "        for word, postings in inv_indx:\n",
    "            f.write(word + ': ' + str(doc_freq[word]) + '\\n')\n",
    "                        \n",
    "            for posting in postings:\n",
    "                f.write(str(posting[0]) + ': ' + str(posting[1]) + '\\n')\n",
    "            f.write('\\n----------------\\n')\n",
    "\n",
    "    # Print the number of tokens, maximum, minimum, and average length of the posting list\n",
    "    num_tokens = len(inv_indx)\n",
    "    postings_lengths = [len(postings) for word, postings in inv_indx]\n",
    "    max_len = max(postings_lengths)\n",
    "    min_len = min(postings_lengths)\n",
    "    avg_len = sum(postings_lengths) / num_tokens\n",
    "    \n",
    "    print(f\"Number of Tokens for {col}:\", num_tokens)\n",
    "    print(f\"Maximum Length of Posting List for {col}:\", max_len)\n",
    "    print(f\"Minimum Length of Posting List for {col}:\", min_len)\n",
    "    print(f\"Average Length of Posting List for {col}:\", avg_len)\n",
    "\n",
    "    # Print the word with the most and least posting list\n",
    "    most_postings = max(inv_indx, key=lambda x: len(x[1]))\n",
    "    least_postings = min(inv_indx, key=lambda x: len(x[1]))\n",
    "    print(\"\\nWord with the most posting list:\", most_postings[0])\n",
    "    print(\"Word with the least posting list:\", least_postings[0])\n",
    "    print('\\n------------\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens for TEXT: 36131\n",
      "Maximum Length of Posting List for TEXT: 26146\n",
      "Minimum Length of Posting List for TEXT: 1\n",
      "Average Length of Posting List for TEXT: 36.80631590600869\n",
      "\n",
      "Word with the most posting list: car\n",
      "Word with the least posting list: shogun\n",
      "\n",
      "------------\n",
      "\n",
      "Number of Tokens for FAVORITE: 17762\n",
      "Maximum Length of Posting List for FAVORITE: 9890\n",
      "Minimum Length of Posting List for FAVORITE: 1\n",
      "Average Length of Posting List for FAVORITE: 25.787749127350523\n",
      "\n",
      "Word with the most posting list: seat\n",
      "Word with the least posting list: curblines\n",
      "\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling the inverted_index function\n",
    "inverted_index('TEXT')\n",
    "inverted_index('FAVORITE')\n",
    "# \n",
    "# Inverted indexes are stored in two separate files:\n",
    "#    FAVORITE_inverted_index.txt\n",
    "#    TEXT_inverted_index.txt\n",
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='skyblue'>FINISH</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
